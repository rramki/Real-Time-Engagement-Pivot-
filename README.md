# ğŸ¯ Real-Time Engagement Pivot
### Exam Hall Non-Verbal Cue Analysis System

A **CPU-optimized** Streamlit application that analyzes non-verbal cues (facial expressions, head posture, eye visibility) and detects engagement drops in real-time from live webcam streams or uploaded exam hall recordings â€” then suggests **actionable invigilator interventions**.

---

## âœ¨ Features

| Feature | Description |
|---|---|
| ğŸ”´ Live Stream | Real-time webcam analysis with frame-by-frame scoring |
| ğŸ“ Video Upload | Analyze recorded exam hall MP4/AVI/MOV files |
| ğŸ‘ Face & Eye Detection | OpenCV Haar Cascade (CPU-friendly) |
| ğŸ¤” Head Posture | Detects head-down / looking away via eye visibility |
| ğŸ“Š Engagement Score | Rolling 0â€“100% score with trend analysis |
| ğŸš¨ Alert System | Critical / Warning / OK status banners |
| ğŸ’¡ Interventions | Context-aware, prioritized invigilator actions |
| âš¡ MediaPipe (Optional) | Enhanced face mesh when available |

---

## ğŸš€ Deploy to Streamlit Cloud (Free)

### Step 1 â€” Push to GitHub
```bash
git init
git add .
git commit -m "Engagement Pivot v1"
git remote add origin https://github.com/YOUR_USERNAME/engagement-pivot.git
git push -u origin main
```

### Step 2 â€” Deploy on Streamlit Cloud
1. Go to [share.streamlit.io](https://share.streamlit.io)
2. Click **New app**
3. Connect your GitHub repo
4. Set **Main file path** to `app.py`
5. Click **Deploy!**

> âš ï¸ **Note on Live Webcam**: Browser webcam access works on HTTPS (Streamlit Cloud provides this). On localhost, it uses `cv2.VideoCapture(0)` directly.

---

## ğŸ’» Run Locally

```bash
# Install dependencies
pip install -r requirements.txt

# Run
streamlit run app.py
```

---

## ğŸ§  How It Works

### Non-Verbal Cue Detection Pipeline

```
Video Frame â†’ Grayscale â†’ Face Detection (Haar Cascade)
                â†“
          Eye Detection (per face ROI)
                â†“
    â”Œâ”€ Eyes visible (2) â†’ ENGAGED
    â”œâ”€ Eyes partial (1) â†’ DISTRACTED  
    â””â”€ Eyes absent (0)  â†’ HEAD DOWN
                â†“
    Engagement Score = f(engaged_ratio, eye_ratio)
                â†“
    Rolling Average â†’ Trend Analysis â†’ Alerts â†’ Interventions
```

### Engagement Score Formula
```python
score = 100
score -= (head_down_count / total_faces) * 40   # Heavy penalty
score -= (distracted_count / total_faces) * 20  # Moderate penalty
score += (eye_ratio - 0.5) * 10                 # Bonus for eye contact
score = clamp(score, 0, 100)
```

### Intervention Tiers
| Score | Priority | Examples |
|---|---|---|
| < 40% | IMMEDIATE | Stretch break, walk the hall |
| 40â€“60% | HIGH | Time reminder, desk taps |
| 60â€“75% | MEDIUM | Patrol, open windows |
| â‰¥ 75% | LOW | Standard monitoring |

---

## âš™ï¸ Settings

| Setting | Effect |
|---|---|
| Sensitivity (1â€“10) | Adjusts alert thresholds |
| Frame Skip (1â€“5) | Skip N frames to reduce CPU load |
| Show CV Annotations | Toggle bounding boxes on/off |
| Exam Duration | Provides exam context |

---

## ğŸ“¦ Dependencies

- **streamlit** â€” UI framework
- **opencv-python-headless** â€” Computer vision (no GUI, Streamlit Cloud compatible)
- **numpy / pandas** â€” Numerical analysis
- **mediapipe** *(optional)* â€” Enhanced face mesh detection
- **Pillow / scipy** â€” Image processing utilities

---

## ğŸ”§ Streamlit Cloud Notes

- Use `opencv-python-headless` (not `opencv-python`) â€” required for cloud
- Webcam in live mode requires browser HTTPS permission prompt
- Video uploads limited to 200MB (configurable in `config.toml`)
- CPU-only: no GPU required

---

## ğŸ“ File Structure

```
engagement-pivot/
â”œâ”€â”€ app.py                    # Main application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml           # Streamlit configuration
```

---

*Built for real-time exam hall engagement monitoring. CPU-optimized for deployment on Streamlit Community Cloud.*
